apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: llm-route
spec:
  parentRefs:
  - group: gateway.networking.k8s.io
    kind: Gateway
    name: inference-gateway
    sectionName: llm-gw
  rules:
  - backendRefs:
    - group: gateway.envoyproxy.io
      kind: Backend
      name: backend-dummy
      weight: 1
    matches:
    - path:
        type: PathPrefix
        value: /v1/chat/completions
    timeouts:
      backendRequest: 24h
      request: 24h
  # Required to route /v1/model calls from openwebui to vllm.
  # Replace POC HTTPRoute with this one.
  - backendRefs:
    - group: ""
      kind: Service
      name: vllm-llama2-7b-pool
      port: 8000
      weight: 1
    matches:
    - path:
        type: PathPrefix
        value: /v1/models
